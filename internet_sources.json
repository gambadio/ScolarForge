[
  {
    "url": "https://www.nature.com/articles/s41746-024-01248-9",
    "author": "Katharina Wenderott, Jim Krups, Fiona Zaruchas & Matthias Weigl",
    "date": "2024-10-04",
    "content": "Effects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis | npj Digital Medicine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    window.dataLayer = [{\"content\":{\"category\":{\"contentType\":\"review article\",\"legacy\":{\"webtrendsPrimaryArticleType\":\"reviews\",\"webtrendsSubjectTerms\":\"health-services;medical-imaging\",\"webtrendsContentCategory\":null,\"webtrendsContentCollection\":null,\"webtrendsContentGroup\":\"npj Digital Medicine\",\"webtrendsContentGroupType\":null,\"webtrendsContentSubGroup\":\"Review Article\",\"status\":null}},\"article\":{\"doi\":\"10.1038/s41746-024-01248-9\"},\"attributes\":{\"cms\":null,\"deliveryPlatform\":\"oscar\",\"copyright\":{\"open\":true,\"legacy\":{\"webtrendsLicenceType\":\"http://creativecommons.org/licenses/by/4.0/\"}}},\"contentInfo\":{\"authors\":[\"Katharina Wenderott\",\"Jim Krups\",\"Fiona Zaruchas\",\"Matthias Weigl\"],\"publishedAt\":1727654400,\"publishedAtString\":\"2024-09-30\",\"title\":\"Effects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis\",\"legacy\":null,\"publishedAtTime\":null,\"documentType\":\"aplusplus\",\"subjects\":\"Health services,Medical imaging\"},\"journal\":{\"pcode\":\"npjdigitalmed\",\"title\":\"npj digital medicine\",\"volume\":\"7\",\"issue\":\"1\",\"id\":41746,\"publishingModel\":\"Open Access\"},\"authorization\":{\"status\":true},\"features\":[{\"name\":\"furtherReadingSection\",\"present\":true}],\"collection\":null},\"page\":{\"category\":{\"pageType\":\"article\"},\"attributes\":{\"template\":\"mosaic\",\"featureFlags\":[{\"name\":\"nature-onwards-journey\",\"active\":false}],\"testGroup\":null},\"search\":null},\"privacy\":{},\"version\":\"1.0.0\",\"product\":null,\"session\":null,\"user\":null,\"backHalfContent\":true,\"country\":\"CH\",\"hasBody\":true,\"uneditedManuscript\":false,\"twitterId\":[\"o3xnx\",\"o43y9\",\"o3ef7\"],\"baiduId\":\"d38bce82bcb44717ccc29a90c4b781ea\",\"japan\":false}];\n    window.dataLayer.push({\n        ga4MeasurementId: 'G-ERRNTNZ807',\n        ga360TrackingId: 'UA-71668177-1',\n        twitterId: ['3xnx', 'o43y9', 'o3ef7'],\n        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',\n        ga4ServerUrl: 'https://collect.nature.com',\n        imprint: 'nature'\n    });\n\n\n\n\n    (function(w, d) {\n        w.config = w.config || {};\n        w.config.mustardcut = false;\n\n        \n        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {\n            w.config.mustardcut = true;\n            d.classList.add('js');\n            d.classList.remove('grade-c');\n            d.classList.remove('no-js');\n        }\n    })(window, document.documentElement);\n\n\n\n@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-card--major .c-card__title,.u-h1,.u-h2,h1,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h3,h4,h5,h6{letter-spacing:-.0117156rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}.c-card--major .c-card__title,.u-h1,.u-h2,button,h1,h2{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}button{border-radius:0;cursor:pointer}.c-card--major .c-card__title,.u-h1,.u-h2,h1,h2{font-weight:700}h1{font-size:2rem;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,h2{font-size:1.5rem;letter-spacing:-.0117156rem;line-height:1.6rem}.u-h3{letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h3,h4,h5,h6{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-reading-companion__figure-title,.u-h4,h3,h4,h5,h6{letter-spacing:-.0117156rem}.c-reading-companion__figure-title,.u-h4,h4{font-size:1.125rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:\", \"}.c-author-list>li:not(:only-child):last-child:before{content:\" & \"}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:\" ... \"}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:\"\";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url(\"data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E\");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:\"\";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-link-inherit{color:inherit}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-text-bold{font-weight:700}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    (function () {\n        if ( typeof window.CustomEvent === \"function\" ) return false;\n        function CustomEvent ( event, params ) {\n            params = params || { bubbles: false, cancelable: false, detail: null };\n            var evt = document.createEvent( 'CustomEvent' );\n            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );\n            return evt;\n        }\n\n        CustomEvent.prototype = window.Event.prototype;\n\n        window.CustomEvent = CustomEvent;\n    })();\n\n\n\n\n\n\n    window.initGTM = function() {\n        if (window.config.mustardcut) {\n            (function (w, d, s, l, i) {\n                w[l] = w[l] || [];\n                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});\n                var f = d.getElementsByTagName(s)[0],\n                        j = d.createElement(s),\n                        dl = l != 'dataLayer' ? '&l=' + l : '';\n                j.async = true;\n                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;\n                f.parentNode.insertBefore(j, f);\n            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');\n        }\n    }\n\n\n\n\n\n\n    (function(w,d,t) {\n        function cc() {\n            var h = w.location.hostname;\n            if (h.indexOf('preview-www.nature.com') > -1) return;\n\n            var e = d.createElement(t),\n                    s = d.getElementsByTagName(t)[0];\n\n            if (h.indexOf('nature.com') > -1) {\n                if (h.indexOf('test-www.nature.com') > -1) {\n                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-68.js';\n                    e.setAttribute('onload', \"initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')\");\n                } else {\n                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-68.js';\n                    e.setAttribute('onload', \"initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')\");\n                }\n            } else {\n                e.src = '/static/js/cookie-consent-es5-bundle-cb57c2c98a.js';\n                e.setAttribute('data-consent', h);\n            }\n            s.insertAdjacentElement('afterend', e);\n        }\n\n        cc();\n    })(window,document,'script');\n\n\n\n\n    (function(w, d) {\n        w.idpVerifyPrefix = 'https://verify.nature.com';\n        w.ra21Host = 'https://wayf.springernature.com';\n        var moduleSupport = (function() {\n            return 'noModule' in d.createElement('script');\n        })();\n\n        if (w.config.mustardcut === true) {\n            w.loader = {\n                index: 0,\n                registered: [],\n                scripts: [\n                    \n                        {src: '/static/js/global-article-es6-bundle-13ad78fd2d.js', test: 'global-article-js', module: true},\n                        {src: '/static/js/global-article-es5-bundle-9d27d3bb31.js', test: 'global-article-js', nomodule: true},\n                        {src: '/static/js/shared-es6-bundle-3c71d44690.js', test: 'shared-js', module: true},\n                        {src: '/static/js/shared-es5-bundle-a656f9aa7b.js', test: 'shared-js', nomodule: true},\n                        {src: '/static/js/header-150-es6-bundle-f67696dc4f.js', test: 'header-150-js', module: true},\n                        {src: '/static/js/header-150-es5-bundle-4986fdbeaa.js', test: 'header-150-js', nomodule: true}\n                    \n                ].filter(function (s) {\n                    if (s.src === null) return false;\n                    if (moduleSupport && s.nomodule) return false;\n                    return !(!moduleSupport && s.module);\n                }),\n\n                register: function (value) {\n                    this.registered.push(value);\n                },\n\n                ready: function () {\n                    if (this.registered.length === this.scripts.length) {\n                        this.registered.forEach(function (fn) {\n                            if (typeof fn === 'function') {\n                                setTimeout(fn, 0); \n                            }\n                        });\n                        this.ready = function () {};\n                    }\n                },\n\n                insert: function (s) {\n                    var t = d.getElementById('js-position' + this.index);\n                    if (t && t.insertAdjacentElement) {\n                        t.insertAdjacentElement('afterend', s);\n                    } else {\n                        d.head.appendChild(s);\n                    }\n                    ++this.index;\n                },\n\n                createScript: function (script, beforeLoad) {\n                    var s = d.createElement('script');\n                    s.id = 'js-position' + (this.index + 1);\n                    s.setAttribute('data-test', script.test);\n                    if (beforeLoad) {\n                        s.defer = 'defer';\n                        s.onload = function () {\n                            if (script.noinit) {\n                                loader.register(true);\n                            }\n                            if (d.readyState === 'interactive' || d.readyState === 'complete') {\n                                loader.ready();\n                            }\n                        };\n                    } else {\n                        s.async = 'async';\n                    }\n                    s.src = script.src;\n                    return s;\n                },\n\n                init: function () {\n                    this.scripts.forEach(function (s) {\n                        loader.insert(loader.createScript(s, true));\n                    });\n\n                    d.addEventListener('DOMContentLoaded', function () {\n                        loader.ready();\n                        var conditionalScripts;\n                        \n                            conditionalScripts = [\n                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-95c366f641.js', test: 'pan-zoom-js',  module: true },\n                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-98fb9b653b.js', test: 'pan-zoom-js',  nomodule: true },\n                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-8d316f606c.js', test: 'math-js', module: true},\n                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-3dd28f5e98.js', test: 'math-js', nomodule: true}\n                            ];\n                        \n\n                        if (conditionalScripts) {\n                            conditionalScripts.filter(function (script) {\n                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));\n                            }).forEach(function (script) {\n                                loader.insert(loader.createScript(script));\n                            });\n                        }\n                    }, false);\n                }\n            };\n            loader.init();\n        }\n    })(window, document);\n\n\n\n\n\n\n\n\n\n\n\n\n\n{\"mainEntity\":{\"headline\":\"Effects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis\",\"description\":\"In healthcare, integration of artificial intelligence (AI) holds strong promise for facilitating clinicians\u2019 work, especially in clinical imaging. We aimed to assess the impact of AI implementation for medical imaging on efficiency in real-world clinical workflows and conducted a systematic review searching six medical databases. Two reviewers double-screened all records. Eligible records were evaluated for methodological quality. The outcomes of interest were workflow adaptation due to AI implementation, changes in time for tasks, and clinician workload. After screening 13,756 records, we identified 48 original studies to be incuded in the review. Thirty-three studies measured time for tasks, with 67% reporting reductions. Yet, three separate meta-analyses of 12 studies did not show significant effects after AI implementation. We identified five different workflows adapting to AI use. Most commonly, AI served as a secondary reader for detection tasks. Alternatively, AI was used as the primary reader for identifying positive cases, resulting in reorganizing worklists or issuing alerts. Only three studies scrutinized workload calculations based on the time saved through AI use. This systematic review and meta-analysis represents an assessment of the efficiency improvements offered by AI applications in real-world clinical imaging, predominantly revealing enhancements across the studies. However, considerable heterogeneity in available studies renders robust inferences regarding overall effectiveness in imaging tasks. Further work is needed on standardized reporting, evaluation of system integration, and real-world data collection to better understand the technological advances of AI in real-world healthcare workflows. Systematic review registration: Prospero ID CRD42022303439, International Registered Report Identifier (IRRID): RR2-10.2196/40485.\",\"datePublished\":\"2024-09-30T00:00:00Z\",\"dateModified\":\"2024-09-30T00:00:00Z\",\"pageStart\":\"1\",\"pageEnd\":\"16\",\"license\":\"http://creativecommons.org/licenses/by/4.0/\",\"sameAs\":\"https://doi.org/10.1038/s41746-024-01248-9\",\"keywords\":[\"Health services\",\"Medical imaging\",\"Medicine/Public Health\",\"general\",\"Biomedicine\",\"Biotechnology\"],\"image\":[\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-024-01248-9/MediaObjects/41746_2024_1248_Fig1_HTML.png\",\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-024-01248-9/MediaObjects/41746_2024_1248_Fig2_HTML.png\",\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-024-01248-9/MediaObjects/41746_2024_1248_Fig3_HTML.png\",\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41746-024-01248-9/MediaObjects/41746_2024_1248_Fig4_HTML.png\"],\"isPartOf\":{\"name\":\"npj Digital Medicine\",\"issn\":[\"2398-6352\"],\"volumeNumber\":\"7\",\"@type\":[\"Periodical\",\"PublicationVolume\"]},\"publisher\":{\"name\":\"Nature Publishing Group UK\",\"logo\":{\"url\":\"https://www.springernature.com/app-sn/public/images/logo-springernature.png\",\"@type\":\"ImageObject\"},\"@type\":\"Organization\"},\"author\":[{\"name\":\"Katharina Wenderott\",\"url\":\"http://orcid.org/0000-0002-6335-4231\",\"affiliation\":[{\"name\":\"University Hospital Bonn\",\"address\":{\"name\":\"Institute for Patient Safety, University Hospital Bonn, Bonn, Germany\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"email\":\"katharina.wenderott@ukbonn.de\",\"@type\":\"Person\"},{\"name\":\"Jim Krups\",\"url\":\"http://orcid.org/0009-0009-8598-2421\",\"affiliation\":[{\"name\":\"University Hospital Bonn\",\"address\":{\"name\":\"Institute for Patient Safety, University Hospital Bonn, Bonn, Germany\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"},{\"name\":\"Fiona Zaruchas\",\"affiliation\":[{\"name\":\"University Hospital Bonn\",\"address\":{\"name\":\"Institute for Patient Safety, University Hospital Bonn, Bonn, Germany\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"},{\"name\":\"Matthias Weigl\",\"affiliation\":[{\"name\":\"University Hospital Bonn\",\"address\":{\"name\":\"Institute for Patient Safety, University Hospital Bonn, Bonn, Germany\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"}],\"isAccessibleForFree\":true,\"@type\":\"ScholarlyArticle\"},\"@context\":\"https://schema.org\",\"@type\":\"WebPage\"}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n        window.eligibleForRa21 = 'false'; \n    \n\n\n\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\n\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertisement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView all journals\n\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\nLog in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplore\n content\n\n\n\n\n\n\n\n\n\n\nAbout \nthe journal\n\n\n\n\n\n\n\n\n\n\nPublish \nwith us\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSign up for alerts\n\n\n\n\n\n\n\n\n\n\nRSS feed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnature\n\n\n\n\n\n\n\n\nnpj digital medicine\n\n\n\n\n\n\n\n\nreview articles\n\n\n\n\n\n\n\n\n\n\narticle\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                        Effects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis\n                    \n\n\n\n\n\n\nDownload PDF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownload PDF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReview Article\n\n\n\n\nOpen access\n\n\n\n\nPublished: \n30 September 2024\n\n\n\n\nEffects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis\n\n\nKatharina Wenderott\n\u00a0\n            \nORCID: \norcid.org/0000-0002-6335-4231\n1\n, \nJim Krups\n\u00a0\n            \nORCID: \norcid.org/0009-0009-8598-2421\n1\n, \nFiona Zaruchas\n1\n & \n\u2026\nMatthias Weigl\n1\n\u00a0\nShow authors\n\n\n\n\nnpj Digital Medicine\n\n\nvolume\n\u00a07\n, Article\u00a0number:\u00a0\n265\n (\n2024\n)\n            \nCite this article\n\n\n\n\n\n\n\n\n\n\n324 \nAccesses\n\n\n\n\n\n\n1 \nAltmetric\n\n\n\n\n\n\nMetrics \ndetails\n\n\n\n\n\n\n\n\n\n\n\n\nSubjects\n\n\n\n\nHealth services\nMedical imaging\n\n\n\n\n\n\n\n\n\n\nAbstract\nIn healthcare, integration of artificial intelligence (AI) holds strong promise for facilitating clinicians\u2019 work, especially in clinical imaging. We aimed to assess the impact of AI implementation for medical imaging on efficiency in real-world clinical workflows and conducted a systematic review searching six medical databases. Two reviewers double-screened all records. Eligible records were evaluated for methodological quality. The outcomes of interest were workflow adaptation due to AI implementation, changes in time for tasks, and clinician workload. After screening 13,756 records, we identified 48 original studies to be incuded in the review. Thirty-three studies measured time for tasks, with 67% reporting reductions. Yet, three separate meta-analyses of 12 studies did not show significant effects after AI implementation. We identified five different workflows adapting to AI use. Most commonly, AI served as a secondary reader for detection tasks. Alternatively, AI was used as the primary reader for identifying positive cases, resulting in reorganizing worklists or issuing alerts. Only three studies scrutinized workload calculations based on the time saved through AI use. This systematic review and meta-analysis represents an assessment of the efficiency improvements offered by AI applications in real-world clinical imaging, predominantly revealing enhancements across the studies. However, considerable heterogeneity in available studies renders robust inferences regarding overall effectiveness in imaging tasks. Further work is needed on standardized reporting, evaluation of system integration, and real-world data collection to better understand the technological advances of AI in real-world healthcare workflows. Systematic review registration: Prospero ID CRD42022303439, International Registered Report Identifier (IRRID): RR2-10.2196/40485.\n\n\n\n\n\n\n\n\nSimilar content being viewed by others\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeterogeneity and predictors of the effects of AI assistance on radiologists\n                                        \n\n\n\n\n\n\nArticle\n\n\nOpen access\n\n\n19 March 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality assessment standards in artificial intelligence diagnostic accuracy systematic reviews: a meta-research study\n                                        \n\n\n\n\n\n\nArticle\n\n\nOpen access\n\n\n27 January 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAn integrative review on the acceptance of artificial intelligence among healthcare professionals in hospitals\n                                        \n\n\n\n\n\n\nArticle\n\n\nOpen access\n\n\n10 June 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                window.dataLayer = window.dataLayer || [];\n                window.dataLayer.push({\n                    recommendations: {\n                        recommender: 'semantic',\n                        model: 'specter',\n                        policy_id: 'NA',\n                        timestamp: 1728072070,\n                        embedded_user: 'null'\n                    }\n                });\n            \n\n\n\n\nIntroduction\nWith a rising number of patients and limited staff available, the need for changes in healthcare is a pressing issue\n1\n. Artificial intelligence (AI) technologies promise to alleviate the current burden by taking over routine tasks, such as monitoring patients, documenting care tasks, providing decision support, and prioritizing patients by analyzing clinical data\n2\n,\n3\n. AI-facilitated innovations are claimed to significantly reduce the workload of healthcare professionals\n4\n,\n5\n.\nSeveral medical specialties have already introduced AI into their routine work, particularly in data-intensive domains, such as genomics, pathology, and radiology\n4\n. In particular, image-based disciplines have seen substantial benefits from the pattern recognition abilities of AI, positioning them at the forefront of AI integration in clinical care\n3\n,\n6\n. AI technologies expedite the processing of an increasing number of medical images, being used for detecting artifacts, malignant cells or other suspicious structures, and optionally for the succeeding prioritization of patients\n7\n,\n8\n,\n9\n.\nTo successfully adopt AI in everyday clinical practice, different ways for effective workflow integration can be conceived, largely depending on the specific aim, that is, enhancing the quality of diagnosis, providing reinsurance, or reducing human workload\n10\n,\n11\n. Efficiency outcomes related to AI implementation include shorter reading times or a reduced workload of clinicians to meet the growing demand for interpreting an increasing number of images\n12\n,\n13\n,\n14\n. Thus, whether AI fulfills these aims and enables higher efficiency in everyday clinical work remains largely unknown.\nHealthcare systems are complex, combining various components and stakeholders that interact with each other\n15\n. While the success of AI technology implementation highly depends on the setting, processes, and users, current studies largely focus on the technical features and capabilities of AI, not on its actual implementation and consequences in the clinical landscape\n2\n,\n3\n,\n6\n,\n16\n,\n17\n. Therefore, this systematic review aimed to examine the influence of AI technologies on workflow efficiency in medical imaging tasks within real-world clinical care settings to account for effects that stem from the complex and everyday demands in real-world clinical care, all not being existent in experimental and laboratory settings\n18\n.\nResults\nStudy selection\nWe identified 22,684 records in databases and an additional 295 articles through backward search. After the removal of duplicates, the 13,756 remaining records were included in the title/abstract screening. Then, 207 full texts were screened, of which 159 were excluded primarily because of inadequate study designs or not focusing on AI for interpreting imaging data (Supplementary Table \n1\n). Finally, 48 studies were included in the review and data extraction. Twelve studies underwent additional meta-analyses. A PRISMA flow chart is presented in Fig. \n1\n.\nFig. 1: PRISMA flowchart.\nVisual representation of the search strategy, data screening and selection process of this systematic review.\nFull size image\nStudy characteristics\nOf the 48 extracted studies, 30 (62.5%) were performed in a single institution, whereas the 18 (37.5%) remaining studies were multicenter studies. One study was published in 2010, another in 2012, and all other included studies were published from 2018 onward. Research was mainly conducted in North America (\nn\n\u2009=\u200921), Europe (\nn\n\u2009=\u200912), Asia (\nn\n\u2009=\u200911), and Australia (\nn\n\u2009=\u20093). Furthermore, one study was conducted across continents. The included studies were stemming from the medical departments of radiology (\nn\n\u2009=\u200926), gastroenterology (\nn\n\u2009=\u20096), oncology (\nn\n\u2009=\u20094), emergency medicine (\nn\n\u2009=\u20094), ophthalmology (\nn\n\u2009=\u20094), human genetics (\nn\n\u2009=\u20091), nephrology (\nn\n\u2009=\u20091), neurology (\nn\n\u2009=\u20091), and pathology (\nn\n\u2009=\u20091). Most studies used computed tomography (CT) for imaging, followed by X-ray and colonoscopes. The most prominent indications were intracranial hemorrhage, followed by pulmonary embolism, and cancer screening. Table \n1\n presents the key characteristics of all included studies.\nTable 1 Key characteristics of included studies\nFull size table\nConcerning the purpose of using AI tools in clinical work, we classified the studies into three main categories. First, five studies (10.4%) described an AI tool used for segmentation tasks (e.g., determining the boundaries or volume of an organ). Second, 25 studies (52.1%) used AI tools to examine detection tasks to identify suspicious cancer nodules or fractures. Third, 18 studies (37.5%) investigated the prioritization of patients according to AI-detected critical features (e.g., reprioritizing the worklist or notifying the treating clinician via an alert).\nRegarding the AI tools described in the studies, 34 studies (70.8%) focused on commercially available solutions (Table \n2\n). Only Pierce et al. did not specify which commercially available algorithm was used\n19\n. Thirteen studies (27.1%) used non-commercially available algorithms, detailed information on these algorithms is provided in Table \n3\n. Different measures were used to evaluate the accuracy of these AI tools, including sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and area under the curve (AUC). Sensitivity and specificity were the most commonly reported measures (see Tables \n2\n and \n3\n).\nTable 2 Overview of the commercial AI tools used in the included studies\nFull size table\nTable 3 Non-commercially available AI algorithms\nFull size table\nIn total only four studies followed a reporting guideline, three studies\n20\n,\n21\n,\n22\n used Standards for Reporting of Diagnostic Accuracy (STARD) reporting guideline\n23\n and Repici et al.\n24\n followed the CONSORT guidelines for randomized controlled trials\n25\n. Only two studies\n24\n,\n26\n pre-registered their protocol and none of the included studies provided or used an open-source available algorithm.\nAppraisal of methodological quality\nWhen assessing the methodological quality of the 45 non-randomized studies only one (2.2%) was rated with an overall \u201clow\u201d risk of bias. Four studies (8.9%) were rated \u201cmoderate\u201d, 28 studies (62.2%) were rated \u201cserious\u201d, and 12 studies (26.7%) were rated \u201ccritical\u201d. All three randomized studies were appraised with an overall high risk of bias. Summary plots of the risk of bias assessments are shown in Fig. \n2\n, full assessments can be found in Supplementary Figs. \n1\n and \n2\n. The assessment of the quality of reporting using the \nMethodological Index for Non-randomized Studies\n (MINORS) is included in Supplementary Figs. \n3\n and \n4\n. Higher scores indicate higher quality of reporting, with the maximum score being 24 for comparative studies and 16 for non-comparative studies\n27\n. Comparative studies reported a Median of 9 of 12 criteria with a median overall score of 15 (range: 9\u201323) and noncomparative studies reported a Median of 7 of 8 checklist items, with a median overall score of 7 (range: 6\u201314).\nFig. 2: Quality assessment of included articles.\nSummary plots of the risk of bias assessments via \nRisk of Bias in Non-randomized Studies of Interventions tool\n (ROBINS-I) for non-randomized studies and the \nCochrane Risk of Bias tool\n (Rob 2) for randomized studies.\nFull size image\nOutcomes\nOf all included studies, 33 (68.8%) surveyed the effects of AI implementation on clinicians\u2019 time for task execution. The most frequently reported outcomes included (1) reading time (i.e., time the clinicians required to interpret an image); (2) report turnaround time (i.e., the time from completing the scan until the report is finalized); and (3) total procedure time (i.e., the time needed for colonoscopy)\n28\n,\n29\n,\n30\n. Times were assessed via surveys, recorded by researchers or staff, retrieved via time stamps, or self-recorded. Seventeen studies did not describe how they obtained the reported times.\nRegarding our research question, whether AI use improves efficiency, 22 studies (66.6%) reported a reduction in time for task completion due to AI use, with 13 of these studies proving the difference to be statistically significant (see Table \n4\n). Eight studies (24.2%) reported that AI did not reduce the time required for tasks. The remaining three studies (9.1%) chose a design or implementation protocol in which the AI was used after the normal reading, increasing the task time measured by study design\n31\n,\n32\n,\n33\n.\nTable 4 Outcomes organized by time type measured\nFull size table\nFor our meta-analyses, we established clusters with studies deploying similar methods, outcomes, and specific purposes. Concerning studies on detection tasks, we identified two main subgroups: studies using AI for interpreting CT scans (\nn\n\u2009=\u20097) and those using AI for colonoscopy (\nn\n\u2009=\u20096). Among studies using AI for interpreting CT images, a meta-analysis was performed for four studies reporting clinicians\u2019 reading times. As shown in Fig. \n3a\n, the reading times for interpreting CT images did not differ between the groups: standardized mean error (SMD): \u22120.60 (95% confidence interval, \u22122.02 to 0.82; \np\n\u2009=\u20090.30). Furthermore, the studies showed significantly high heterogeneity: Q\u2009=\u2009109.72, \np\n\u2009<\u20090.01, I\n2\n\u2009=\u200996.35%. This heterogeneity may be associated with the different study designs included or the risk of bias ratings, with only one study being rated having a low risk of bias. Furthermore, Mueller et al.\n8\n reported no overall reading time but separated it for resident and attending physician, which we included separately in our meta-analysis. Concerning the use of AI for colonoscopy, five studies reported comparable measures. Our random effects meta-analysis showed no significant difference between the groups: SMD: \u22120.04 (95% CI, \u22120.76 to 0.67; \np\n\u2009=\u20090.87), with significant heterogeneity: Q\u2009=\u2009733.51, \np\n\u2009<\u20090.01, I\n2\n\u2009=\u200999.45% (Fig. \n3b\n). Four of the included studies had a serious risk of bias, whereas one randomized study included was rated with a high risk of bias. Among 11 studies that reported AI use for the prioritization of patients\u2019 scans, four measured the turnaround time. The study by Batra et al.\n34\n did not report variance measures and was therefore excluded from the meta-analysis. The remaining three studies used the AI tool Aidoc (Tables \n2\n and \n4\n) to detect intracranial hemorrhage and reported the turnaround time for cases flagged positive. The meta-analysis showed no significant difference in turnaround time between cases with and without AI use: SMD: 0.03 (95% CI, \u22120.50 to 0.56; \np\n\u2009=\u20090.84), with a significant heterogeneity across studies: Q\u2009=\u200912.31, \np\n\u2009<\u20090.01, I\n2\n\u2009=\u200983.75% (Fig. \n3c\n). All included studies were non-randomized studies, with two studies being rated with a serious risk of bias and one with a moderate risk of bias.\nFig. 3: Results of meta-analyses.\nGraphical display and statistical results of the three meta-analyses: \na\n Studies using AI for detection tasks in CT images and reported clinicians\u2019 reading time. \nb\n Studies using AI to detect polyps during colonoscopy and measured the total procedure time. \nc\n Studies that used AI for reprioritization and measured the turnaround times for cases flagged positive. All included studies used AIDOC for intracranial hemorrhage detection.\nFull size image\nIn total, 37 studies reported details on the actual workflow adaptations due to AI implementation, which we classified into four main variants (depicted exemplarily in Fig. \n4\n). 16 studies (43.2%) used an AI tool as a triage system, i.e., the AI tool reprioritized the worklist or the AI tool sent an alert to the clinician or referred the patient to a specialist for further examination (Fig. \n4a\n: AI triage). In two studies (5.4%), the AI tool acted as a gatekeeper, only referring cases labeled as suspicious to the clinician for further review, while excluding the remaining cases (Fig. \n4a\n: AI gatekeeper). In 13 studies (35.1%), AI tools were used as a second reader for detection tasks in two variants (Fig. \n4b\n: AI second reader). Eight studies reported that the AI tool functioned as a second reader in a concurrent mode, presenting additional information during the task to clinicians (e.g., in colonoscopy studies, where the workflow remained the same as before displaying additional information during the procedure). Five studies described a workflow in which the AI tool was used additionally after the normal detection task, resulting in a sequential second reader workflow. In five segmentation studies (13.5%), the AI tool served as a first reader with the clinician reviewing and then correcting the AI-provided contours (Fig. \n4c\n: AI first reader).\nFig. 4: Prototypical workflows after AI implementation.\nVisual representation of the different workflows when using AI as reported in the included studies: \na\n Workflows when using AI for prioritization tasks. \nb\n Workflow when using AI for detection. \nc\n Workflow when using AI for segmentation tasks. Figure created with Canva (Canva Pty Ltd, Sydney, Australia).\nFull size image\nIn a single study (2.7%), the type of actual workflow implementation was at the radiologist\u2019s choice. Three studies used a study design with the AI tool as a second reader in a pre-specified reading sequence; therefore, we did not classify them as workflow adaptations. The remaining studies did not provide sufficient information on workflow implementation.\nIn our initial review protocol, we also aimed to include investigations on clinician workload\n14\n. Apart from three studies, Liu et al.\n35\n, Raya-Povedano et al.\n36\n, and Yacoub et al.\n37\n, which calculated the saved workload in scans or patients because of AI use, no other study reported AI implementation effects on clinicians\u2019 workload (besides the time for tasks effects, see above). Other reported outcomes included evaluations of the AI performing the task (i.e., satisfaction)\n8\n,\n38\n; frequency of AI use\n29\n,\n30\n; patient outcomes, such as length of stay or in-hospital complications\n39\n,\n40\n; and sensitivity or specificity changes\n8\n,\n21\n,\n24\n,\n28\n,\n41\n.\nRisk of bias across studies\nFunnel plots for the studies included in the meta-analyses were created (Supplementary Figs. \n5\n\u2013\n7\n). 19 studies declared a relevant conflict of interest and six other studies had potential conflicts of interest, which sum up to more than 50% of the included studies.\nAdditionally, we ran several sensitivity analyses to evaluate for potential selection bias. We first searched the dblp computer science bibliography, yielding 1159 studies for title and abstract screening. Therein, we achieved perfect interrater reliability (100%). Subsequently, only thirteen studies proceeded to full-text screening, with just one meeting our review criteria. This study by Wismueller & Stockmaster\n42\n was also part of our original search. Notably, this study was the only conference publication providing a full paper (refer to Supplementary Table \n2\n).\nMoreover, to ensure comprehensive coverage and to detect potentially missed publications due to excluding conference proceedings, we screened 2614 records from IEEE Xplore, MICCAI, and HICSS. Once again, our title and abstract screening demonstrated perfect interrater reliability (100%). However, despite including 31 publications in full-text screening, none met our inclusion criteria upon thorough assessment. Altogether, this additionally searches showed no significant indication for a potential selection bias and potentially missing out key work in other major scientific publication outlets.\nUsing AMSTAR-2 (A MeaSurement Tool to Assess Systematic Reviews)\n43\n, we rated the overall confidence in the results as low, mainly due to our decision to combine non-randomized and randomized studies within our meta-analysis (Supplementary Fig. \n8\n).\nDiscussion\nGiven the widespread adoption of AI technologies in clinical work, our systematic review and meta-analysis assesses efficiency effects on routine clinical work in medical imaging. Although most studies reported positive effects, our three meta-analyses with subsets of comparable studies showed no evidence of AI tools reducing the time on imaging tasks. Studies varied substantially in design and measures. This high heterogeneity renders robust inferences. Although nearly 67% of time-related outcome studies have shown a decrease in time with AI use, a noteworthy portion of these studies revealed conflicts of interest, potentially influencing study design or outcome estimation\n44\n. Our findings emphasize the need for comparable and independent high-quality studies on AI implementation to determine its actual effect on clinical workflows.\nFocusing on how AI tools were integrated into the clinical workflow, we discovered diverse adoptions of AI applications in clinical imaging. Some studies have provided brief descriptions that lack adequate details to comprehend the process. Despite predictions of AI potentially supplanting human readers or serving as gatekeepers, with humans primarily reviewing flagged cases to enhance efficiency\n10\n,\n11\n, we noted a limited adoption of AI in this manner across studies. In contrast, most studies reported AI tools as supplementary readers, potentially extending the time taken for interpretation when radiologists must additionally incorporate AI-generated results\n18\n,\n45\n. Another practice involved concurrent reading, which seems beneficial because it guides clinicians\u2019 attention to crucial areas, which potentially improves reading quality and safety without lengthening reading times\n45\n,\n46\n. Regardless of how AI was used, a crucial factor is its alignment with the intended purpose and task\n15\n.\nAlthough efficiency stands out in the current literature, we were also interested in whether AI affects clinicians\u2019 workload, besides the time measurements, such as number of tasks or cognitive load. We only found three studies on AI\u2019s impact on clinicians\u2019 workload, but no study assessed workload separately (e.g., in terms of cognitive workload changes)\n18\n,\n35\n,\n36\n,\n37\n. This gap in research is remarkable since human\u2013technology interaction and human factors assessment will be a success factor for the adoption of AI in healthcare\n47\n,\n48\n.\nOur study included a vast variety of AI solutions reported in the publications. The majority was a large number of commercially available AI solutions which mostly had acquired FDA or CE clearance, ensuring safety of use in a medical context\n49\n. Nevertheless, it is desirable that future studies provide more detailed information about the accuracy of the AI solutions in their use case or processing times, which both can be crucial to AI adoption\n50\n. Regarding included studies which used non-commercially available algorithms, some of the studies did not specify the origin or source of the algorithm (i.e., developer). Especially with the specific characteristics and potential bias being introduced through the specific algorithm (e.g., for example stemming from a training bias or gaps in the underlying data), it is essential to provide information about the origins and prior validation steps of the algorithm in clinical use\n51\n,\n52\n. Interestingly, only four included studies discussed the possibility of bias in the AI algorithm\n53\n,\n54\n,\n55\n,\n56\n. Open science principles, such as data or code sharing, aid to mitigate the impact of bias. Yet, none of the studies in our review used open-source solutions or provided their algorithm\n52\n. Additionally, guidelines such as CONSORT-AI or SPIRIT-AI provide recommendations for the reporting of clinical studies using AI solutions\n57\n, as previous systematic reviews have also identified serious gaps in the reporting on clinical AI solutions\n58\n,\n59\n. Our results corroborate this shortcoming, as none of the studies reporting non-commercial algorithms and only four studies overall followed a reporting guideline. Notwithstanding, for some included studies, AI-specific reporting guidelines were published after their initial publication. Nevertheless, comprehensive and transparent reporting remains insufficient.\nWith our review, we were able to replicate some of the findings by Yin et al., who provided a first overview on AI solutions in clinical practice, e.g., insufficient reporting in included studies\n60\n. By providing time for tasks and meta-analyses as well as workflow descriptions our review substantially extends the scope of their review, providing a robust and detailed overview on the efficiency effects of AI solutions. In 2020, Nagendran et al. provided a review comparing AI algorithms for medical imaging and clinicians, concluding that only few prospective studies in clinical settings exist\n59\n. Our systematic review demonstrated an increase in real-world studies in previous years and provides an up-to-date and comprehensive overview on AI solutions currently used in medical imaging practice. Our study thereby addresses one of the previously mentioned shortcomings, that benefits of the AI algorithm in silico or in retrospective studies might not transfer into clinical benefit\n59\n. This is also recognized by Han et al.\n61\n who evaluated randomized controlled trials evaluating AI in clinical practice and who argued that efficiency outcomes will strongly depend on implementation processes in actual clinical practice.\nThe complexities of transferring AI solutions from research into practice were explored in a review by Hua et al.\n62\n who evaluated the acceptability AI for medical imaging by healthcare professionals. We believe that for AI to unfold its full potential, it is essential to pay thorough attention to the adoption challenges and work system integration in clinical workplaces. Notwithstanding the increasing number of studies on AI use in real-world settings during the last years, many questions on AI implementation and workflow integration remain unanswered. On the one hand, limited consideration prevails on acceptance of AI solutions by professionals\n62\n. Although studies even discuss the possibility of AI as a teammate in the future\n63\n,\n64\n, most available studies rarely include perceptions of affected clinicians\n60\n. On the other hand, operational and technical challenges as well as system integration into clinical IT infrastructures are major challenges, as many of the described algorithms are cloud-based. Smooth interoperability between new AI technologies and local clinical information systems as well as existing IT infrastructure is key to efficient clinical workflows\n50\n. For example, the combination of multimodal data, such as imaging and EHR data, could be beneficial for future decision processes in healthcare\n65\n.\nOur review has several limitations. First, publication bias may have contributed to the high number of positive findings in our study. Second, despite searching multiple databases, selection bias may have occurred, particularly as some clinics implementing AI do not systematically assess or publish their processes in scientific formats\n60\n. Moreover, we excluded conference publications which could be the source for potential biases. Nevertheless, we ran different sensitivity analyses for publication and selection bias, and did not find evidence for major bias introduced due to our search and identification strategy. Yet, aside from one conference paper, all other conference publications merely provided abstracts or posters, lacking a comprehensive base for the extraction of required details. Third, we focused exclusively on medical imaging tasks to enhance the internal validity of clinical tasks across diverse designs, AI solutions, and workflows. Fourth, the low quality rating of our review on the AMSTAR-2 checklist, which is due to the diverse study designs we included, calling for more comparable high quality studies in this field. Nevertheless, we believe that our review provides a thorough summary of the available studies matching our research question. Finally, our review concentrated solely on efficiency outcomes stemming from the integration of AI into clinical workflows. Yet, the actual impact of AI algorithms on efficiency gains in routine clinical work can be influenced by further, not here specified local factors, e.g., existent IT infrastructure, computational resources, processing times. Next to the testing of the AI solutions under standardized conditions or in randomized controlled trials, which can indicate whether AI solution are suitable for the transfer into routine medical care, careful evaluations of how AI solutions fit into everyday clinical workflow should be expanded, i.e., ideally before implementation. Exploring adoption procedures along with identifying key implementation facilitators and barriers provides valuable insights into successful AI technology use in clinical routines. However, it is important to note that AI implementation can address a spectrum of outcomes, including but not limited to enhancing patient quality and safety, augmenting diagnostic confidence, and improving healthcare staff satisfaction\n8\n.\nIn conclusion, our review showed a positive trend toward research on actual AI implementation in medical imaging, with most studies describing efficiency improvements in course of AI technology implementation. We derive important recommendations for future studies on the implementation of AI in clinical settings. The rigorous use of reporting guidelines should be encouraged, as many studies reporting time outcomes did not provide sufficient details on their methods. Providing a protocol or clear depiction of how AI tools modify clinical workflows allows comprehension and comparison between pre- and post-adoption processes while facilitating learning and future implementation practice. Considering the complexity of healthcare systems, understanding the factors contributing to successful AI implementation is invaluable. Our review corroborates the need for comparable evaluations to monitor and quantify efficiency effects of AI in clinical real-world settings. Finally, future research should therefore explore success and potential differences between different AI algorithms in controlled trials as well as in real-world clinical practice settings to inform and guide future implementation processes.\nMethods\nRegistration and protocol\nBefore its initiation, our systematic literature review was registered in a database (PROSPERO, ID: CRD42022303439), and the review protocol was peer-reviewed (International Registered Report Identifier RR2-10.2196/40485)\n14\n. Our reporting adheres to the Preferred Reporting Items for Systematic Review and Meta-Analysis (PRISMA) statement reporting guidelines (Supplementary Table \n3\n). During the preparation of this work, we used ChatGPT (version GPT-3.5, OpenAI) to optimize the readability and wording of the manuscript. After using this tool, the authors reviewed and edited the content as required and take full responsibility for the content of the publication.\nSearch strategy and eligibility criteria\nArticles were retrieved through a structured literature search in the following electronic databases: MEDLINE (PubMed), Embase, PsycINFO, Web of Science, IEEE Xplore, and Cochrane Central Register of Controlled Trials. We included original studies on clinical imaging, written in German or English, retrieved in full-text, and published in peer-reviewed journals from the 1st of January 2000 onward, which marked a new area of AI in healthcare with the development of deep learning\n14\n,\n66\n. The first search was performed on July 21st, 2022, and was updated on May 19th, 2023. Furthermore, a snowball search screening of the references of the identified studies was performed to retrieve relevant studies. Dissertations, conference proceedings, and gray literature were excluded. This review encompassed observational and interventional studies, such as randomized controlled trials and nonrandomized studies on interventions (e.g., before\u2013after studies). Only studies that introduced AI to actual real-life clinical workflows were eligible, that is, those not conducted in an experimental setting or in a laboratory. The search strategy followed the PICO framework:\n\n\n\n\nPopulation: This review included studies conducted in real-world healthcare facilities, such as hospitals and clinics, using medical imaging and surveying healthcare professionals of varying expertise and qualifications.\n\n\n\n\n\n\nExposure/interventions: This review encompassed studies that focused on various AI tools for diagnostics and their impact on healthcare professionals\u2019 interaction with the technology across various clinical imaging tasks\n67\n. We exclusively focused on AI tools that interpret image data for disease diagnosis and screening\n5\n. For data extraction, we used the following working definition of AI used for clinical diagnostics: \u201cany computer system used to interpret imaging data to make a diagnosis or screen for a disease, a task previously reserved for specialists\u201d\n14\n.\n\n\n\n\n\n\nComparators: This review emphasized studies comparing the workflow before AI use with that after AI use or the workflow with AI use with that without AI use, although this was not a mandatory criterion to be included in the review.\n\n\n\n\n\n\nOutcomes: The primary aim of this study was to evaluate how AI solutions impact workflow efficiency in clinical care contexts. Thus, we focused on three outcomes of interest: (1) changes in time required for task completion, (2) workflow adaptation, and (3) workload.\n\n\n\n\n\n\n\n\n(1)\n\n\nChanges in time\n for completion of imaging tasks were considered, focusing on reported quantitative changes attributed to AI usage (e.g., throughput times and review duration).\n\n\n\n\n\n\n(2)\n\n\nWorkflow adaptation\n encompasses changes in the workflow that result from the introduction of new technologies, particularly in the context of AI implementation (i.e., specifying the time and purpose of AI use).\n\n\n\n\n\n\n(3)\n\n\nWorkload\n refers to the demands of tasks on human operators and changes associated with AI implementation (e.g., cognitive demands or task load).\n\n\n\n\nThe detailed search strategy following the PICO framework can be found in Supplementary Table \n4\n and Supplementary Note \n1\n.\nScreening and selection procedure\nAll retrieved articles were imported into the \nRayyan tool\n68\n,\n69\n for title and abstract screening. In the first step, after undergoing a training, two study team members (KW and JK/MW/NG) independently screened the titles and abstracts to establish interrater agreement. In the second step, the full texts of all eligible publications were screened by KW and JK. Any potential conflicts regarding the inclusion of articles were resolved through discussions with a third team member (MW). Reasons for exclusion were documented, as depicted in the flow diagram in Fig. \n1\n70\n.\nData extraction procedure\nTwo authors (JK and KW/FZ) extracted the study data and imported them into MS Excel which then went through random checks by a study team member (MW). To establish agreement all reviewers extracted data from the first five studies based on internal data extraction guidelines.\nStudy quality appraisal and risk of bias assessment\nTo evaluate the methodological quality of the included studies, two reviewers (KW and JK) used three established tools. The \nRisk of Bias in Non-randomized Studies of Interventions tool\n (ROBINS-I) for non-randomized studies and the \nCochrane Risk of Bias tool\n (Rob 2) for randomized studies were used\n71\n,\n72\n. To assess the reporting quality of the included studies, the MINORS was used\n27\n. The MINORS was used instead of the Quality of Reporting of Observational Longitudinal Research checklist\n73\n, as pre-specified in the review protocol, because this tool was more adaptable to all included studies. Appraisals were finally established through discussion until consensus was achieved.\nStrategy for data synthesis\nFirst, we describe the overall sample and the key information from each included study. Risk of bias assessment evaluations are presented in narrative and tabular formats. Next, where comparable studies were sufficient, a meta-analysis was performed to examine the effects of AI introduction. We used the method of Wan et al.\n74\n to estimate the sample mean and standard deviation from the sample size, median, and interquartile range because the reported measures varied across the included studies. Furthermore, we followed the Cochrane Handbook for calculating the standard deviation from the confidence interval (CI)\n75\n. The \nmetafor\n package in R\n76\n was used to quantitatively synthesize data from the retrieved studies. Considering the anticipated heterogeneity of effects, a random-effects model was used to estimate the average effect across studies. Moreover, we used the DerSimonian and Laird method to determine cross-study variance and the Hartung\u2013Knapp method to estimate the variance of the random effect\n77\n,\n78\n. Heterogeneity was assessed using Cochran\u2019s \nQ\n test\n79\n and the I\n2\n statistic\n75\n. In cases where a meta-analysis was not feasible, the results were summarized in narrative form and presented in tabular format.\nMeta-biases\nPotential sources of meta-bias, such as publication bias and selective reporting across studies, were considered. Funnel plots were created for the studies included in the meta-analyses.\nTo assess whether our review is subject to selection bias due to the choice of databases and publication types, we conducted an additional search in the dblp computer science bibliography (with our original search timeframe). As this database did not allow our original search string, the adapted version is found in Supplementary Note \n2\n. Additionally, we performed searches on conference proceedings of the last three years, spanning publications from the January 1st 2020 until May 15th 2023. We surveyed IEEE Xplore and two major conferences not included in the database: International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI) and Hawaii International Conference on System Sciences (HICSS). We conducted an initial screening of titles and abstracts, with one reviewer (KW) screening all records and JK screening 10% to assess interrater reliability. Full-text assessments for eligibility were then performed by one of the reviewers, respectively (KW or JK). Furthermore, the AMSTAR-2 critical appraisal tool for systematic reviews of randomized and/or non-randomized healthcare intervention studies was used\n43\n.\n\n\n\n\n\n\nData availability\n\n\nAll data generated or analyzed during this study is available from the corresponding author upon reasonable request.\n\n\nCode availability\n\n\nCode for meta-analyses available via \nhttps://github.com/katwend/metaanalyses\n.\n\n\nReferences\nYeganeh, H. An analysis of emerging trends and transformations in global healthcare. \nIJHG\n \n24\n, 169\u2013180 (2019).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nAsan, O., Bayrak, A. E. & Choudhury, A. Artificial intelligence and human trust in healthcare: focus on clinicians. \nJ. Med. Internet Res.\n \n22\n, e15154 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nPark, C.-W. et al. Artificial intelligence in health care: current applications and issues. \nJ. Korean Med. Sci.\n \n35\n, e379 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nAhmad, Z., Rahim, S., Zubair, M. & Abdul-Ghafar, J. Artificial Intelligence (ai) in medicine, current applications and future role with special emphasis on its potential and promise in pathology: present and future impact, obstacles including costs and acceptance among pathologists, practical and philosophical considerations. a comprehensive review. \nDiagn. Pathol.\n \n16\n, 24 (2021).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHe, J. et al. The practical implementation of artificial intelligence technologies in medicine. \nNat. Med.\n \n25\n, 30\u201336 (2019).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWong, S. H., Al-Hasani, H., Alam, Z. & Alam, A. Artificial intelligence in radiology: how will we be affected? \nEur. Radiol.\n \n29\n, 141\u2013143 (2019).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nArbabshirani, M. R. et al. Advanced machine learning in action: identification of intracranial hemorrhage on computed tomography scans of the head with clinical workflow integration. \nnpj Digit. Med.\n \n1\n, 9 (2018).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nMueller, F. C. et al. Impact of concurrent use of artificial intelligence tools on radiologists reading time: a prospective feasibility study. \nAcad. Radiol.\n \n29\n, 1085\u20131090 (2022).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nPumplun, L., Fecho, M., Wahl, N., Peters, F. & Buxmann, P. Adoption of machine learning systems for medical diagnostics in clinics: qualitative interview study. \nJ. Med. Internet Res.\n \n23\n, e29301 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDahlblom, V., Dustler, M., Tingberg, A. & Zackrisson, S. Breast cancer screening with digital breast tomosynthesis: comparison of different reading strategies implementing artificial intelligence. \nEur. Radiol.\n \n33\n, 3754\u20133765 (2023).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nMiyake, M. et al. Comparative performance of a primary-reader and second-reader paradigm of computer-aided detection for CT colonography in a low-prevalence screening population. \nJpn J. Radio.\n \n31\n, 310\u2013319 (2013).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHosny, A., Parmar, C., Quackenbush, J., Schwartz, L. H. & Aerts, H. J. W. L. Artificial intelligence in radiology. \nNat. Rev. Cancer\n \n18\n, 500\u2013510 (2018).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nvan Leeuwen, K. G., de Rooij, M., Schalekamp, S., van Ginneken, B. & Rutten, M. J. C. M. How does artificial intelligence in radiology improve efficiency and health outcomes? \nPediatric Radiol.\n \n52\n, 2087\u20132093 (2021).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWenderott, K., Gambashidze, N. & Weigl, M. Integration of artificial intelligence into sociotechnical work systems\u2014effects of artificial intelligence solutions in medical imaging on clinical efficiency: protocol for a systematic literature review. \nJMIR Res. Protoc.\n \n11\n, e40485 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSalwei, M. E. & Carayon, P. A Sociotechnical systems framework for the application of artificial intelligence in health care delivery. \nJ. Cogn. Eng. Decis. Making\n \n16\n, 194\u2013206 (2022).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWolff, J., Pauling, J., Keck, A. & Baumbach, J. Success factors of artificial intelligence Implementation in Healthcare. \nFront. Digit. Health\n \n3\n, 594971 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nFelmingham, C. M. et al. The importance of incorporating human factors in the design and implementation of artificial intelligence for skin cancer diagnosis in the real world. \nAm. J. Clin. Dermatol.\n \n22\n, 233\u2013242 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWenderott, K., Krups, J., Luetkens, J. A., Gambashidze, N. & Weigl, M. Prospective effects of an artificial intelligence-based computer-aided detection system for prostate imaging on routine workflow and radiologists\u2019 outcomes. \nEur. J. Radiol.\n \n170\n, 111252 (2024).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nPierce, J. et al. Seamless integration of artificial intelligence into the clinical environment: our experience with a novel pneumothorax detection artificial intelligence algorithm. \nJ. Am. Coll. Radiol.\n \n18\n, 1497\u20131505 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDiao, K. et al. Diagnostic study on clinical feasibility of an AI-based diagnostic system as a second reader on mobile CT images: a preliminary result. \nAnn. Transl. Med.\n \n10\n, 668 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDuron, L. et al. Assessment of an AI aid in detection of adult appendicular skeletal fractures by emergency physicians and radiologists: a multicenter cross-sectional diagnostic study. \nRadiology\n \n300\n, 120\u2013129 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nKanagasingam, Y. et al. Evaluation of artificial intelligence\u2013based grading of diabetic retinopathy in primary care. \nJAMA Netw. Open\n \n1\n, e182665 (2018).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nBossuyt, P. M. et al. STARD 2015: an updated list of essential items for reporting diagnostic accuracy studies. \nRadiology\n \n277\n, 826\u2013832 (2015).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nRepici, A. et al. Efficacy of real-time computer-aided detection of colorectal neoplasia in a randomized trial. \nGastroenterology\n \n159\n, 512\u2013520.e7 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSchulz, K. F., Altman, D. G. & Moher, D. CONSORT Group CONSORT 2010 Statement: updated guidelines for reporting parallel group randomised trials. \nBMJ\n \n340\n, c332\u2013c332 (2010).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWang, P. et al. Real-time automatic detection system increases colonoscopic polyp and adenoma detection rates: a prospective randomised controlled study. \nGut\n \n68\n, 1813\u20131819 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSlim, K. et al. Methodological index for non-randomized studies (MINORS): development and validation of a new instrument: methodological index for non-randomized studies. \nANZ J. Surg.\n \n73\n, 712\u2013716 (2003).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nConant, E. F. et al. Improving accuracy and efficiency with concurrent use of artificial intelligence for digital breast tomosynthesis. \nRadiol. Artif. Intell.\n \n1\n, e180096 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nNehme, F. et al. Performance and attitudes toward real-time computer-aided polyp detection during colonoscopy in a large tertiary referral center in the United States. \nGastrointest. Endosc.\n \n98\n, 100\u2013109.e6 (2023).\nZia, A. et al. Retrospective analysis and prospective validation of an Ai-based software for intracranial haemorrhage detection at a high-volume trauma centre. \nSci. Rep.\n \n12\n, 19885 (2022).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nTchou, P. M. et al. Interpretation time of computer-aided detection at screening mammography. \nRadiology\n \n257\n, 40\u201346 (2010).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nVassallo, L. et al. A cloud-based computer-aided detection system improves identification of lung nodules on computed tomography scans of patients with extra-thoracic malignancies. \nEur. Radiol.\n \n29\n, 144\u2013152 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWittenberg, R. et al. Acute pulmonary embolism: effect of a computer-assisted detection prototype on diagnosis\u2014an observer study. \nRadiology\n \n262\n, 305\u2013313 (2012).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nBatra, K., Xi, Y., Bhagwat, S., Espino, A. & Peshock, R. Radiologist worklist reprioritization using artificial intelligence: impact on report turnaround times for CTPA examinations positive for acute pulmonary embolism. \nAm. J. Roentgenol\n \n221\n, 324\u2013333 (2023).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nLiu, X. et al. Evaluation of an OCT-AI-based telemedicine platform for retinal disease screening and referral in a primary care setting. \nTransl. Vis. Sci. Technol.\n \n11\n, 4 (2022).\nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nRaya-Povedano, J. L. et al. AI-based strategies to reduce workload in breast cancer screening with mammography and tomosynthesis: a retrospective evaluation. \nRadiology\n \n300\n, 57\u201365 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nYacoub, B. et al. Impact of artificial intelligence assistance on chest CT interpretation times: a prospective randomized study. \nAm. J. Roentgenol.\n \n219\n, 743\u2013751 (2022).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nCha, E. et al. Clinical implementation of deep learning contour auto segmentation for prostate radiotherapy. \nRadiother. Oncol.\n \n159\n, 1\u20137 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDavis, M. A., Rao, B., Cedeno, P. A., Saha, A. & Zohrabian, V. M. Machine learning and improved quality metrics in acute intracranial hemorrhage by noncontrast computed tomography. \nCurr. Probl. Diagn. Radiol.\n \n51\n, 556\u2013561 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHassan, A., Ringheanu, V. & Tekle, W. The implementation of artificial intelligence significantly reduces door-in-door-out times in a primary care center prior to transfer. \nInterv. Neuroradiol.\n \n29\n, 631\u2013636 (2022).\nLadabaum, U. et al. Computer-aided detection of polyps does not improve colonoscopist performance in a pragmatic implementation trial. \nGastroenterol\n. \n164\n, 481\u2013483 (2023).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWism\u00fcller, A. & Stockmaster, L. A Prospective randomized clinical trial for measuring radiology study reporting time on artificial intelligence-based detection of intracranial hemorrhage in emergent Care Head CT (2020).\nShea, B. J. et al. Amstar 2: a critical appraisal tool for systematic reviews that include randomised or non-randomised studies of healthcare interventions, or both. \nBMJ\n \n358\n, j4008 (2017).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nBoutron, I. et al. Considering bias and conflicts of interest among the included studies. In \nCochrane Handbook for Systematic Reviews of Interventions\n (eds Higgins, J. P. T. et al.) 177\u2013204 (Wiley, 2019).\nBeyer, F. et al. Comparison of sensitivity and reading time for the use of computer-aided detection (CAD) of pulmonary nodules at MDCT as concurrent or second reader. \nEur. Radio.\n \n17\n, 2941\u20132947 (2007).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nFujita, H. AI-based computer-aided diagnosis (AI-CAD): the latest review to read first. \nRadio. Phys. Technol.\n \n13\n, 6\u201319 (2020).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nAsan, O. & Choudhury, A. Research trends in artificial intelligence applications in human factors health care: mapping review. \nJMIR Hum. Factors\n \n8\n, e28236 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHerrmann, T. & Pfeiffer, S. Keeping the organization in the loop: a socio-technical extension of human-centered artificial intelligence. \nAI Soc.\n \n38\n, 1523\u20131542 (2023).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nAllen, B. The role of the FDA in ensuring the safety and efficacy of artificial intelligence software and devices. \nJ. Am. Coll. Radiol.\n \n16\n, 208\u2013210 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWenderott, K., Krups, J., Luetkens, J. A. & Weigl, M. Radiologists\u2019 perspectives on the workflow integration of an artificial intelligence-based computer-aided detection system: a qualitative study. \nAppl. Ergon.\n \n117\n, 104243 (2024).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nNazer, L. H. et al. Bias in artificial intelligence algorithms and recommendations for mitigation. \nPLOS Digit Health\n \n2\n, e0000278 (2023).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nNorori, N., Hu, Q., Aellen, F. M., Faraci, F. D. & Tzovara, A. Addressing bias in big data and AI for health care: a call for open science. \nPatterns\n \n2\n, 100347 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nChen, W. et al. Improving the diagnosis of acute ischemic stroke on non-contrast Ct using deep learning: a multicenter study. \nInsights Imaging\n \n13\n, 184 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nPotretzke, T. et al. Clinical implementation of an artificial intelligence algorithm for magnetic resonance-derived measurement of total kidney volume. \nMayo Clin. Proc.\n \n98\n, 689\u2013700 (2023).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSun, J. et al. Performance of a chest radiograph AI diagnostic tool for COVID-19: a prospective observational study. \nRadiol. Artif. Intell.\n \n4\n, e210217 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nTricarico, D. et al. Convolutional neural network-based automatic analysis of chest radiographs for the detection of COVID-19 pneumonia: a prioritizing tool in the emergency department, phase i study and preliminary \u2018real life\u2019 results. \nDiagnostics\n \n12\n, 570 (2022).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nIbrahim, H. et al. Reporting guidelines for clinical trials of artificial intelligence interventions: the SPIRIT-AI and CONSORT-AI guidelines. \nTrials\n \n22\n, 11 (2021).\nLiu, X. et al. A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis. \nLancet Digit. Health\n \n1\n, e271\u2013e297 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nNagendran, M. et al. Artificial intelligence versus clinicians: systematic review of design, reporting standards, and claims of deep learning studies. \nBMJ\n m689 (2020).\nYin, J., Ngiam, K. Y. & Teo, H. H. Role of artificial intelligence applications in real-life clinical practice: systematic review. \nJ. Med. Internet Res.\n \n23\n, e25759 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHan, R. et al. Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review. \nLancet Digit. Health\n \n6\n, e367\u2013e373 (2024).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHua, D., Petrina, N., Young, N., Cho, J.-G. & Poon, S. K. Understanding the factors influencing acceptability of AI in medical imaging domains among healthcare professionals: a scoping review. \nArtif. Intell. Med.\n \n147\n, 102698 (2024).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nBruni, S., Freiman, M. & Riddle, K. Beyond the tool vs. teammate debate: exploring the sidekick metaphor in human-AI Dyads. In: Julia Wright and Daniel Barber (eds) Human Factors and Simulation. AHFE (2023) International Conference. AHFE Open Access, \n83\n (2023).\nFlathmann, C. et al. Examining the impact of varying levels of AI teammate influence on human-AI teams. \nInt. J. Hum.-Comput. Stud.\n \n177\n, 103061 (2023).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHuang, S.-C., Pareek, A., Seyyedi, S., Banerjee, I. & Lungren, M. P. Fusion of medical imaging and electronic health records using deep learning: a systematic review and implementation guidelines. \nnpj Digit. Med.\n \n3\n, 136 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nKaul, V., Enslin, S. & Gross, S. A. History of artificial intelligence in medicine. \nGastrointest. Endosc.\n \n92\n, 807\u2013812 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDias, R. & Torkamani, A. Artificial intelligence in clinical and genomic diagnostics. \nGenome Med.\n \n11\n, 70 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nOuzzani, M., Hammady, H., Fedorowicz, Z. & Elmagarmid, A. Rayyan-a web and mobile app for systematic reviews. \nSyst. Rev.\n \n5\n, 210 (2016).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nOuzzani, M., Hammady, H., Fedorowicz, Z. & Elmagarmid, A. Rayyan-a web and mobile app for systematic reviews. \nSyst Rev.\n \n5\n, 210 (2016).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nPage, M. J. et al. The Prisma 2020 statement: an updated guideline for reporting systematic reviews. \nBMJ\n \n372\n, n71 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSterne, J. A. et al. ROBINS-I: a tool for assessing risk of bias in non-randomised studies of interventions. \nBMJ\n \n355\n, i4919 (2016).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSterne, J. A. C. et al. RoB 2: a revised tool for assessing risk of bias in randomised trials. \nBMJ\n \n366\n, l4898 (2019).\nTooth, L., Ware, R., Bain, C., Purdie, D. M. & Dobson, A. Quality of reporting of observational longitudinal research. \nAm. J. Epidemiol.\n \n161\n, 280\u2013288 (2005).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWan, X., Wang, W., Liu, J. & Tong, T. Estimating the sample mean and standard deviation from the sample size, median, range and/or interquartile range. \nBMC Med Res Methodol.\n \n14\n, 135 (2014).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHiggins, J. P. T., Thompson, S. G., Deeks, J. J. & Altman, D. G. Measuring inconsistency in meta-analyses. \nBMJ\n \n327\n, 557\u2013560 (2003).\nViechtbauer, W. Conducting meta-analyses in R with the metafor Package. \nJ Stat Softw.\n \n36\n, 1\u201348 (2010).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDerSimonian, R. & Laird, N. Meta-analysis in clinical trials. \nControl. Clin. Trials\n \n7\n, 177\u2013188 (1986).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHartung, J. An alternative method for meta-analysis. \nBiom. J. J. Math. Methods Biosci.\n \n41\n, 901\u2013916 (1999).\n\n                    Google Scholar\n\u00a0\n                \nCochran, W. G. The combination of estimates from different experiments. \nBiometrics\n \n10\n, 101 (1954).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nCarlile, M. et al. Deployment of artificial intelligence for radiographic diagnosis of COVID-19 pneumonia in the emergency department. \nJ. Am. Coll. Emerg. Phys. Open\n \n1\n, 1459\u20131464 (2020).\n\n                    Google Scholar\n\u00a0\n                \nCheikh, A. B. et al. How artificial intelligence improves radiological interpretation in suspected pulmonary embolism. \nEur. Radiol.\n \n32\n, 5831\u20135842 (2022).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nElijovich, L. et al. Automated emergent large vessel occlusion detection by artificial intelligence improves stroke workflow in a hub and spoke stroke system of care. \nJ. NeuroIntervent Surg.\n \n14\n, 704\u2013708 (2022).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nGinat, D. Implementation of machine learning software on the radiology worklist decreases scan view delay for the detection of intracranial hemorrhage on CT. \nBrain Sci.\n \n11\n, 832 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nHong, W. et al. Deep learning for detecting pneumothorax on chest radiographs after needle biopsy: clinical implementation. \nRadiology\n \n303\n, 433\u2013441 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nJones, C. M. et al. Assessment of the effect of a comprehensive chest radiograph deep learning model on radiologist reports and patient outcomes: a real-world observational study. \nBMJ Open\n \n11\n, e052902 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nKiljunen, T. et al. A deep learning-based automated CT segmentation of prostate cancer anatomy for radiation therapy planning-A retrospective multicenter study. \nDiagnostics\n \n10\n, 959 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nLevy, I., Bruckmayer, L., Klang, E., Ben-Horin, S. & Kopylov, U. Artificial intelligence-aided colonoscopy does not increase adenoma detection rate in routine clinical practice. \nAm. J. Gastroenterol.\n \n117\n, 1871\u20131873 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nMarwaha, A., Chitayat, D., Meyn, M., Mendoza-Londono, R. & Chad, L. The point-of-care use of a facial phenotyping tool in the genetics clinic: enhancing diagnosis and education with machine learning. \nAm. J. Med. Genet. A\n \n185\n, 1151\u20131158 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nO\u2019Neill, T. J. et al. Active reprioritization of the reading worklist using artificial intelligence has a beneficial effect on the turnaround time for interpretation of head CT with intracranial hemorrhage. \nRadiol. Artif. Intell.\n \n3\n, e200024 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nOppenheimer, J., L\u00fcken, S., Hamm, B. & Niehues, S. A prospective approach to integration of AI fracture detection software in radiographs into clinical workflow. \nLife (Basel, Switzerland)\n \n13\n, 223 (2023).\nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nQuan, S. Y. et al. Clinical evaluation of a real-time artificial intelligence-based polyp detection system: a US multi-center pilot study. \nSci. Rep.\n \n12\n, 6598 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nRuamviboonsuk, P. et al. Real-time diabetic retinopathy screening by deep learning in a multisite national screening programme: a prospective interventional cohort study. \nLancet Digit. Health\n \n4\n, e235\u201344 (2022).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSandbank, J. et al. Validation and real-world clinical application of an artificial intelligence algorithm for breast cancer detection in biopsies. \nnpj Breast Cancer\n \n8\n, 129 (2022).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSchmuelling, L. et al. Deep learning-based automated detection of pulmonary embolism on CT pulmonary angiograms: no significant effects on report communication times and patient turnaround in the emergency department nine months after technical implementation. \nEur. J. Radiol.\n \n141\n, 109816 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSeyam, M. et al. Utilization of artificial intelligence-based intracranial hemorrhage detection on emergent noncontrast CT images in clinical workflow. \nRadiol. Artif. Intell.\n \n4\n, e210168 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nSim, J. Z. T. et al. Diagnostic performance of a deep learning model deployed at a National COVID-19 screening facility for detection of pneumonia on frontal chest radiographs. \nHealthcare\n \n10\n, 175 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nStrolin, S. et al. How smart is artificial intelligence in organs delineation? Testing a CE and FDA-approved deep-learning tool using multiple expert contours delineated on planning CT images. \nFront. Oncol.\n \n13\n, 1089807 (2023).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWang, M. et al. Deep learning-based triage and analysis of lesion burden for COVID-19: a retrospective study with external validation. \nLancet Digit. Health\n \n2\n, e506\u2013e515 (2020).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWong, J. et al. Implementation of deep learning-based auto-segmentation for radiotherapy planning structures: a workflow study at two cancer centers. \nRadiat. Oncol.\n \n16\n, 101 (2021).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWong, K. et al. Integration and evaluation of chest X-ray artificial intelligence in clinical practice. \nJ. Med. Imaging\n \n10\n, 051805 (2023).\nArticle\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nYang, Y. et al. Performance of the AIDRScreening system in detecting diabetic retinopathy in the fundus photographs of Chinese patients: a prospective, multicenter, clinical study. \nAnn. Transl. Med.\n \n10\n, 1088 (2022).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nElguindi, S. et al. Deep learning-based auto-segmentation of targets and organs-at-risk for magnetic resonance imaging only planning of prostate radiotherapy. \nPhys. Imaging Radiat. Oncol.\n \n12\n, 80\u201386 (2019).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nWang, L. et al. An intelligent optical coherence tomography-based system for pathological retinal cases identification and urgent referrals. \nTrans. Vis. Sci. Tech.\n \n9\n, 46 (2020).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nGulshan, V. et al. Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs. \nJAMA\n \n316\n, 2402 (2016).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nKrause, J. et al. Grader variability and the importance of reference standards for evaluating machine learning models for diabetic retinopathy. \nOphthalmology\n \n125\n, 1264\u20131272 (2018).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nRuamviboonsuk, P. et al. Deep learning versus human graders for classifying diabetic retinopathy severity in a nationwide screening program. \nnpj Digit. Med.\n \n2\n, 25 (2019).\nArticle\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nRetico, A., Delogu, P., Fantacci, M. E., Gori, I. & Preite Martinez, A. Lung nodule detection in low-dose and thin-slice computed tomography. \nComput. Biol. Med.\n \n38\n, 525\u2013534 (2008).\nArticle\n\u00a0\n    \nCAS\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nLopez Torres, E. et al. Large scale validation of the M5L lung CAD on heterogeneous CT datasets. \nMed. Phys.\n \n42\n, 1477\u20131489 (2015).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \nPubMed Central\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nBrown, M. S. et al. Automated endotracheal tube placement check using semantically embedded deep neural networks. \nAcad. Radiol.\n \n30\n, 412\u2013420 (2023).\nArticle\n\u00a0\n    \nPubMed\n\u00a0\n    \n\n                    Google Scholar\n\u00a0\n                \nDownload references\nAcknowledgements\nWe sincerely thank Dr. Nikoloz Gambashidze (Institute for Patient Safety, University Hospital Bonn) for helping with the title and abstract screening. We thank Annika Str\u00f6mer (Institute for Medical Biometry, Informatics and Epidemiology, University of Bonn) for her statistical support. This research was financed through institutional budget, i.e., no external funding.\nFunding\nOpen Access funding enabled and organized by Projekt DEAL.\nAuthor information\nAuthors and Affiliations\nInstitute for Patient Safety, University Hospital Bonn, Bonn, Germany\nKatharina Wenderott,\u00a0Jim Krups,\u00a0Fiona Zaruchas\u00a0&\u00a0Matthias Weigl\nAuthors\nKatharina Wenderott\nView author publications\nYou can also search for this author in\n                        \nPubMed\n\u00a0\nGoogle Scholar\nJim Krups\nView author publications\nYou can also search for this author in\n                        \nPubMed\n\u00a0\nGoogle Scholar\nFiona Zaruchas\nView author publications\nYou can also search for this author in\n                        \nPubMed\n\u00a0\nGoogle Scholar\nMatthias Weigl\nView author publications\nYou can also search for this author in\n                        \nPubMed\n\u00a0\nGoogle Scholar\nContributions\nK.W.: conceptualization, data curation, formal analysis, investigation, methodology, project administration, software, visualization, writing \u2013 original draft, writing \u2013 preparation, review, and editing; J.K.: data curation, investigation, visualization, writing \u2013 review and editing; F.Z.: investigation, writing \u2013 review and editing; M.W.: conceptualization, funding acquisition, supervision, validation. All authors have read and approved the manuscript.\nCorresponding author\nCorrespondence to\n                \nKatharina Wenderott\n.\nEthics declarations\n\n\nCompeting interests\n\n\nThe authors declare no competing interests.\n\n\nAdditional information\nPublisher\u2019s note\n Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nSupplementary information\nSupplementary Information\nRights and permissions\n\n\nOpen Access\n  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article\u2019s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit \nhttp://creativecommons.org/licenses/by/4.0/\n.\n\n\nReprints and permissions\nAbout this article\nCite this article\nWenderott, K., Krups, J., Zaruchas, F. \net al.\n Effects of artificial intelligence implementation on efficiency in medical imaging\u2014a systematic literature review and meta-analysis.\n                    \nnpj Digit. Med.\n \n7\n, 265 (2024). https://doi.org/10.1038/s41746-024-01248-9\nDownload citation\nReceived\n: \n03 April 2024\nAccepted\n: \n31 August 2024\nPublished\n: \n30 September 2024\nDOI\n: \nhttps://doi.org/10.1038/s41746-024-01248-9\nShare this article\nAnyone you share the following link with will be able to read this content:\nGet shareable link\nSorry, a shareable link is not currently available for this article.\nCopy to clipboard\n\n                            Provided by the Springer Nature SharedIt content-sharing initiative\n                        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDownload PDF\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdvertisement\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExplore content\n\n\n\n\n\n\n\n                                    Research articles\n                                \n\n\n\n\n\n\n\n                                    Reviews & Analysis\n                                \n\n\n\n\n\n\n\n                                    News & Comment\n                                \n\n\n\n\n\n\n\n                                    Collections\n                                \n\n\n\n\n\n\n\n\n\n\nFollow us on Twitter\n                            \n\n\n\n\n\n\nSign up for alerts\n\n\n\n\n\n\n\n\n\n\nRSS feed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbout the journal\n\n\n\n\n\n\n\n                                    Aims and scope\n                                \n\n\n\n\n\n\n\n                                    Content types\n                                \n\n\n\n\n\n\n\n                                    Journal Information\n                                \n\n\n\n\n\n\n\n                                    About the Editors\n                                \n\n\n\n\n\n\n\n                                    Contact\n                                \n\n\n\n\n\n\n\n                                    Editorial policies\n                                \n\n\n\n\n\n\n\n                                    Calls for Papers\n                                \n\n\n\n\n\n\n\n                                    Journal Metrics\n                                \n\n\n\n\n\n\n\n                                    About the Partner\n                                \n\n\n\n\n\n\n\n                                    Open Access\n                                \n\n\n\n\n\n\n\n                                    Early Career Researcher Editorial Fellowship\n                                \n\n\n\n\n\n\n\n                                    Editorial Team Vacancies\n                                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPublish with us\n\n\n\n\n\n\n\n                                    For Authors and Referees\n                                \n\n\n\n\n\n\n\n                                    Language editing services\n                                \n\n\n\n\n\n\nSubmit manuscript\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\nSearch articles by subject, keyword or author\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShow results from\n\n\n\n\nAll journals\n\n\nThis journal\n\n\n\n\n\n\n\n\nSearch\n\n\n\n\n\n\n\n\n\n\n\n\n\n                Advanced search\n            \n\n\n\n\nQuick links\n\n\n\n\nExplore articles by subject\n\n\nFind a job\n\n\nGuide to authors\n\n\nEditorial policies\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n                    npj Digital Medicine (\nnpj Digit. Med.\n)\n                \n\n\n\n\nISSN\n \n2398-6352\n (online)\n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnature.com sitemap\n\n\n\n\n\n\n\n\nAbout Nature Portfolio\n\n\n\n\nAbout us\n\n\nPress releases\n\n\nPress office\n\n\nContact us\n\n\n\n\n\n\n\n\nDiscover content\n\n\n\n\nJournals A-Z\n\n\nArticles by subject\n\n\nprotocols.io\n\n\nNature Index\n\n\n\n\n\n\n\n\nPublishing policies\n\n\n\n\nNature portfolio policies\n\n\nOpen access\n\n\n\n\n\n\n\n\nAuthor & Researcher services\n\n\n\n\nReprints & permissions\n\n\nResearch data\n\n\nLanguage editing\n\n\nScientific editing\n\n\nNature Masterclasses\n\n\nResearch Solutions\n\n\n\n\n\n\n\n\nLibraries & institutions\n\n\n\n\nLibrarian service & tools\n\n\nLibrarian portal\n\n\nOpen research\n\n\nRecommend to library\n\n\n\n\n\n\n\n\nAdvertising & partnerships\n\n\n\n\nAdvertising\n\n\nPartnerships & Services\n\n\nMedia kits\n\n\n\n\nBranded\n                        content\n\n\n\n\n\n\n\n\nProfessional development\n\n\n\n\nNature Careers\n\n\nNature\n \n\n                        Conferences\n\n\n\n\n\n\n\n\nRegional websites\n\n\n\n\nNature Africa\n\n\nNature China\n\n\nNature India\n\n\nNature Italy\n\n\nNature Japan\n\n\nNature Middle East\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrivacy\n                Policy\n\n\nUse\n                of cookies\n\n\n\n\nYour privacy choices/Manage cookies\n                \n\n\n\n\nLegal\n                notice\n\n\nAccessibility\n                statement\n\n\nTerms & Conditions\n\n\nYour US state privacy rights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u00a9 2024 Springer Nature Limited\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClose banner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClose\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSign up for the \nNature Briefing\n newsletter \u2014 what matters in science, free to your inbox daily.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmail address\n\n\n\n\n\n\n\n\nSign up\n\n\n\n\n\n\n\n\nI agree my information will be processed in accordance with the \nNature\n and Springer Nature Limited \nPrivacy Policy\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClose banner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClose\n\n\n\n\n\n\n\n\nGet the most important science stories of the day, free in your inbox.\n\n\nSign up for Nature Briefing"
  }
]